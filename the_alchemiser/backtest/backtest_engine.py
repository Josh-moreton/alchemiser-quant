#!/usr/bin/env python3
"""
Clean Backtest Engine for The Alchemiser

Features:
- Individual strategy backtests (Nuclear, TECL, KLM)
- Multi-strategy backtests using config weights
- All possible 3-strategy weight combinations
- Multithreading for faster execution
- Enhanced data caching to prevent API rate limits
- Sensible defaults for slippage and market noise
- Deposit functionality support
- Clean, focused API

Usage:
    # Pre-load data once (IMPORTANT - call this first!)
    preload_backtest_data(start_date, end_date, include_minute_data=False)
    
    # Individual strategy
    results = run_individual_strategy_backtest('nuclear', start, end)
    
    # Config-based multi-strategy
    results = run_config_backtest(start, end)
    
    # All weight combinations (now uses cached data!)
    results = run_all_combinations_backtest(start, end)
"""
import os
import time
import datetime as dt
import pandas as pd
import numpy as np
import copy
import argparse
from typing import Dict, List, Tuple, Optional, Union
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from dataclasses import dataclass
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import track, Progress, SpinnerColumn, TextColumn

# Hardcoded Alpaca credentials for local testing
os.environ['ALPACA_PAPER_KEY'] = 'PKS7WB1KB6VVG72FF8VZ'
os.environ['ALPACA_PAPER_SECRET'] = 'Ibcd2Zy98HL3wabRMQW6R0T1SnSZ2vN1uoLWhIOQ'

from the_alchemiser.core.trading.strategy_manager import MultiStrategyManager, StrategyType
from the_alchemiser.core.data.data_provider import UnifiedDataProvider
from the_alchemiser.core import config as alchemiser_config

# Import the new caching system
from the_alchemiser.backtest.data_cache import (
    get_global_cache, preload_backtest_data, get_cached_symbol_data, clear_global_cache
)

import os
import datetime as dt
import pandas as pd
import numpy as np
import copy
from typing import Dict, List, Tuple, Optional, Union
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import track, Progress, SpinnerColumn, TextColumn

# Hardcoded Alpaca credentials for local testing
os.environ['ALPACA_PAPER_KEY'] = 'PKS7WB1KB6VVG72FF8VZ'
os.environ['ALPACA_PAPER_SECRET'] = 'Ibcd2Zy98HL3wabRMQW6R0T1SnSZ2vN1uoLWhIOQ'

from the_alchemiser.core.trading.strategy_manager import MultiStrategyManager, StrategyType
from the_alchemiser.core.data.data_provider import UnifiedDataProvider
from the_alchemiser.core import config as alchemiser_config

console = Console()

# Sensible defaults
DEFAULT_INITIAL_EQUITY = 1000.0
DEFAULT_SLIPPAGE_BPS = 8  # 8 basis points (0.08%) - realistic for retail trading
DEFAULT_NOISE_FACTOR = 0.0015  # 0.15% market noise


def _get_cached_symbol_data(symbols, start, end, fetch_minute_data=False):
    """
    Get symbol data from cache instead of hitting API repeatedly.
    
    This function replaces the old _preload_symbol_data and uses the global cache
    to avoid repeated API calls across multiple backtest workers.
    """
    cache = get_global_cache()
    
    symbol_data = {}
    symbol_minute_data = {}
    
    console.print(f"[green]üìÇ Loading {len(symbols)} symbols from cache...[/green]")
    
    missing_symbols = []
    
    for sym in symbols:
        # Get daily data from cache
        daily_df = cache.get_symbol_data(sym, 'daily')
        if daily_df is not None and not daily_df.empty:
            # Filter to requested date range
            start_filter = start
            end_filter = end
            
            # Handle timezone awareness safely
            try:
                # Check if index has timezone info
                index_tz = getattr(daily_df.index, 'tz', None)
                if index_tz is not None:
                    if start.tzinfo is None:
                        import pytz
                        start_filter = pytz.timezone('US/Eastern').localize(start)
                    if end.tzinfo is None:
                        end_filter = pytz.timezone('US/Eastern').localize(end)
                else:
                    if start.tzinfo is not None:
                        start_filter = start.replace(tzinfo=None)
                    if end.tzinfo is not None:
                        end_filter = end.replace(tzinfo=None)
            except Exception:
                # Fallback if timezone detection fails
                start_filter = start
                end_filter = end
            
            # Filter to date range
            mask = (daily_df.index >= start_filter) & (daily_df.index <= end_filter)
            filtered_df = daily_df[mask]
            
            if not filtered_df.empty:
                symbol_data[sym] = filtered_df
            else:
                missing_symbols.append(f"{sym} (no data in range)")
        else:
            missing_symbols.append(f"{sym} (not cached)")
        
        # Get minute data from cache if requested
        if fetch_minute_data:
            minute_df = cache.get_symbol_data(sym, 'minute')
            if minute_df is not None and not minute_df.empty:
                # Apply same date filtering
                mask = (minute_df.index >= start_filter) & (minute_df.index <= end_filter)
                filtered_minute_df = minute_df[mask]
                if not filtered_minute_df.empty:
                    symbol_minute_data[sym] = filtered_minute_df
    
    console.print(f"[green]‚úÖ Loaded {len(symbol_data)} symbols from cache[/green]")
    if missing_symbols:
        console.print(f"[yellow]‚ö†Ô∏è Missing {len(missing_symbols)} symbols: {missing_symbols[:5]}{'...' if len(missing_symbols) > 5 else ''}[/yellow]")
    
    return symbol_data, symbol_minute_data


def _preload_symbol_data(data_provider, symbols, start, end, fetch_minute_data=False):
    """
    DEPRECATED: Use cached data instead.
    
    This function is kept for backward compatibility but now redirects to
    the cached version to prevent API rate limits.
    """
    console.print(f"[yellow]‚ö†Ô∏è Using legacy _preload_symbol_data - consider using cached data instead[/yellow]")
    return _get_cached_symbol_data(symbols, start, end, fetch_minute_data)


def _calculate_slippage_cost(weight_change, price, slippage_bps=None):
    """Calculate transaction cost based on weight change and slippage - reusing proven logic"""
    if abs(weight_change) < 1e-6:  # No meaningful trade
        return 0.0
    if slippage_bps is None:
        try:
            from the_alchemiser.core.config import get_config
            config = get_config()
            slippage_bps = config['alpaca'].get('slippage_bps', 5)
        except Exception:
            slippage_bps = 5
    # Slippage cost = (slippage_bps / 10000) * abs(weight_change)
    return (slippage_bps / 10000) * abs(weight_change)


def _add_market_noise(price, volatility_factor=0.001):
    """Add realistic market noise to execution prices - reusing proven logic"""
    noise = np.random.normal(0, volatility_factor)
    return price * (1 + noise)


def run_core_backtest(start, end, strategy_weights=None, initial_equity=1000.0, 
                     slippage_bps=None, noise_factor=0.001, deposit_amount=0.0, 
                     deposit_frequency=None, deposit_day=1, use_minute_candles=False):
    """
    Core backtest function - reusing proven working logic from test_backtest.py
    
    Args:
        start: Start date
        end: End date
        strategy_weights: Dict with 'nuclear', 'tecl', 'klm' weights (None = use config)
        initial_equity: Starting capital
        slippage_bps: Transaction costs in basis points
        noise_factor: Market execution noise
        deposit_amount: Regular deposit amount
        deposit_frequency: 'monthly' or 'weekly'
        deposit_day: Day for deposits
        use_minute_candles: Use minute data for execution
        
    Returns:
        List of daily equity values (equity curve)
    """
    # Set slippage default
    if slippage_bps is None:
        try:
            from the_alchemiser.core.config import get_config
            config = get_config()
            slippage_bps = config['alpaca'].get('slippage_bps', 5)
        except Exception:
            slippage_bps = 5
    
    # Temporarily modify config if strategy weights provided
    orig_global_config = alchemiser_config._global_config
    config_modified = False
    
    if strategy_weights:
        mock_config = alchemiser_config.Config()
        mock_config._config = copy.deepcopy(mock_config._config)
        if 'strategy' not in mock_config._config:
            mock_config._config['strategy'] = {}
        mock_config._config['strategy']['default_strategy_allocations'] = strategy_weights
        alchemiser_config._global_config = mock_config
        config_modified = True
    
    try:
        # Initialize components
        dp = UnifiedDataProvider(paper_trading=True, cache_duration=0)
        manager = MultiStrategyManager(shared_data_provider=dp)
        
        # Get all required symbols
        all_syms = list(set(
            manager.nuclear_engine.all_symbols + 
            manager.tecl_engine.all_symbols +
            (manager.klm_ensemble.all_symbols if hasattr(manager, 'klm_ensemble') and manager.klm_ensemble else [])
        ))
        
        # Preload data using working approach
        lookback_days = 400 if use_minute_candles else 1200
        data_start = start - dt.timedelta(days=lookback_days)
        symbol_data, symbol_minute_data = _get_cached_symbol_data(
            all_syms, data_start, end, fetch_minute_data=use_minute_candles
        )
        
        if not symbol_data:
            raise ValueError("No symbol data loaded - check data provider and symbols")
        
        # Get actual trading dates from market data
        all_trading_dates = set()
        for sym in ['SPY', 'QQQ']:
            if sym in symbol_data and not symbol_data[sym].empty:
                df = symbol_data[sym]
                # Convert naive datetime to timezone-aware if needed
                start_tz = start
                end_tz = end
                if df.index.tz is not None:
                    # Data has timezone, make our dates timezone-aware
                    import pytz
                    if start.tzinfo is None:
                        start_tz = pytz.timezone('US/Eastern').localize(start)
                    if end.tzinfo is None:
                        end_tz = pytz.timezone('US/Eastern').localize(end)
                else:
                    # Data is timezone-naive, ensure our dates are too
                    if start.tzinfo is not None:
                        start_tz = start.replace(tzinfo=None)
                    if end.tzinfo is not None:
                        end_tz = end.replace(tzinfo=None)
                        
                date_mask = (df.index >= start_tz) & (df.index <= end_tz)
                all_trading_dates.update(df.index[date_mask])
        
        date_range = sorted(all_trading_dates)
        
        if not date_range:
            raise ValueError(f"No trading data found for period {start.date()} to {end.date()}")
        
        # Initialize backtest variables
        equity = initial_equity
        equity_curve = [equity]
        prev_weights = {sym: 0 for sym in all_syms}
        
        # Run backtest day by day
        for current_day in track(date_range, description="Processing trading days"):
            # Handle deposits
            if deposit_amount and deposit_frequency:
                if deposit_frequency == 'monthly' and current_day.day == deposit_day:
                    equity += deposit_amount
                elif deposit_frequency == 'weekly' and current_day.weekday() == deposit_day:
                    equity += deposit_amount
            
            # Mock data for current day (historical data up to current_day) - CRITICAL OPTIMIZATION
            dp.cache.clear()
            original_fetch_method = dp._fetch_historical_data
            
            def mock_fetch_historical_data(symbol, period="1y", interval="1d"):
                """Mock method that uses preloaded data instead of API calls - 10x speed boost"""
                if symbol in symbol_data:
                    df = symbol_data[symbol]
                    # For backtesting, provide all available historical data up to current_day
                    # This ensures indicators like 200-day MA have enough data to work with
                    slice_df = df[df.index < current_day]
                    return slice_df
                else:
                    return pd.DataFrame()
            
            dp._fetch_historical_data = mock_fetch_historical_data
            
            # Get strategy signals for current day
            try:
                signals, portfolio = manager.run_all_strategies()
                current_weights = {sym: portfolio.get(sym, 0.0) for sym in all_syms}
            except Exception as e:
                console.print(f"[yellow]Warning: Strategy error on {current_day.date()}: {e}")
                # Use previous weights if strategy fails
                current_weights = prev_weights.copy()
            finally:
                # Always restore original method
                dp._fetch_historical_data = original_fetch_method
            
            # Calculate and apply slippage costs
            total_slippage = 0.0
            for symbol, new_weight in current_weights.items():
                old_weight = prev_weights.get(symbol, 0.0)
                weight_change = abs(new_weight - old_weight)
                
                if weight_change > 1e-6 and symbol in symbol_data:
                    df = symbol_data[symbol]
                    if current_day in df.index:
                        try:
                            price = float(df.loc[current_day, 'Close'])
                            if price > 0:
                                price_with_noise = _add_market_noise(price, noise_factor)
                                slippage = _calculate_slippage_cost(weight_change, price_with_noise, slippage_bps)
                                total_slippage += slippage
                        except (ValueError, TypeError):
                            continue
            
            equity *= (1 - total_slippage)
            
            # Calculate daily portfolio return
            daily_return = 0.0
            for symbol, weight in current_weights.items():
                if weight == 0 or symbol not in symbol_data:
                    continue
                
                df = symbol_data[symbol]
                if current_day not in df.index:
                    continue
                
                # Get previous trading day
                prev_dates = df.index[df.index < current_day]
                if len(prev_dates) == 0:
                    continue
                
                prev_day = prev_dates[-1]
                try:
                    prev_price = float(df.loc[prev_day, 'Close'])
                    curr_price = float(df.loc[current_day, 'Close'])
                    
                    if prev_price > 0:
                        symbol_return = (curr_price - prev_price) / prev_price
                        daily_return += weight * symbol_return
                except (ValueError, TypeError):
                    continue
            
            equity = float(equity * (1 + daily_return))
            equity_curve.append(equity)
            prev_weights = current_weights.copy()
        
        return equity_curve
        
    finally:
        # Restore original config
        if config_modified:
            alchemiser_config._global_config = orig_global_config


@dataclass
class BacktestResult:
    """Clean container for backtest results"""
    strategy_name: str
    weights: Dict[str, float]
    initial_equity: float
    final_equity: float
    total_return: float
    cagr: float
    volatility: float
    sharpe_ratio: float
    max_drawdown: float
    calmar_ratio: float
    trading_days: int
    equity_curve: List[float]


def calculate_performance_metrics(equity_curve, initial_equity, trading_days):
    """Calculate performance metrics from equity curve"""
    if len(equity_curve) < 2:
        return 0, 0, 0, 0, 0, 0
    
    final_equity = equity_curve[-1]
    total_return = (final_equity / initial_equity - 1) * 100
    
    # Time-based metrics
    n_years = trading_days / 252.0 if trading_days > 0 else 1
    cagr = ((final_equity / initial_equity) ** (1 / n_years) - 1) * 100 if n_years > 0 else 0
    
    # Risk metrics
    daily_returns = [equity_curve[i]/equity_curve[i-1] - 1 for i in range(1, len(equity_curve))]
    if len(daily_returns) > 1:
        volatility = pd.Series(daily_returns).std() * (252**0.5) * 100  # Annualized
        sharpe_ratio = (total_return / 100) / (volatility / 100) * (252**0.5) if volatility > 0 else 0
        
        # Max drawdown
        equity_series = pd.Series(equity_curve)
        running_max = equity_series.cummax()
        drawdown = (equity_series - running_max) / running_max
        max_drawdown = drawdown.min() * 100
        
        calmar_ratio = cagr / abs(max_drawdown) if max_drawdown < 0 else float('inf')
    else:
        volatility = sharpe_ratio = max_drawdown = calmar_ratio = 0
    
    return total_return, cagr, volatility, sharpe_ratio, max_drawdown, calmar_ratio
def run_individual_strategy_backtest(strategy, start, end, 
                                    initial_equity=DEFAULT_INITIAL_EQUITY,
                                    slippage_bps=DEFAULT_SLIPPAGE_BPS,
                                    noise_factor=DEFAULT_NOISE_FACTOR,
                                    deposit_amount=0.0,
                                    deposit_frequency=None,
                                    deposit_day=1,
                                    use_minute_candles=False):
    """
    Backtest a single strategy in isolation
    
    Args:
        strategy: 'nuclear', 'tecl', or 'klm'
        start: Start date
        end: End date
        initial_equity: Starting capital (default: ¬£1000)
        slippage_bps: Transaction costs in basis points (default: 8 bps)
        noise_factor: Market execution noise (default: 0.15%)
        deposit_amount: Regular deposit amount (default: 0)
        deposit_frequency: 'monthly' or 'weekly' (default: None)
        deposit_day: Day for deposits (default: 1)
        use_minute_candles: Use minute data for execution
        
    Returns:
        BacktestResult for the individual strategy
    """
    valid_strategies = ['nuclear', 'tecl', 'klm']
    if strategy.lower() not in valid_strategies:
        raise ValueError(f"Strategy must be one of {valid_strategies}")
    
    strategy = strategy.lower()
    weights = {s: 1.0 if s == strategy else 0.0 for s in valid_strategies}
    
    console.print(Panel(
        f"[bold cyan]Individual Strategy Backtest: {strategy.upper()}[/bold cyan]\n"
        f"Period: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\n"
        f"Initial Equity: ¬£{initial_equity:,.2f}\n"
        f"Slippage: {slippage_bps} bps | Noise: {noise_factor*100:.2f}%",
        title=f"üìä {strategy.upper()} Strategy Test"
    ))
    
    # Run core backtest
    equity_curve = run_core_backtest(
        start, end, weights, initial_equity, slippage_bps, noise_factor,
        deposit_amount, deposit_frequency, deposit_day, use_minute_candles
    )
    
    # Calculate metrics
    total_return, cagr, volatility, sharpe_ratio, max_drawdown, calmar_ratio = \
        calculate_performance_metrics(equity_curve, initial_equity, len(equity_curve) - 1)
    
    return BacktestResult(
        strategy_name=f"{strategy.upper()} (100%)",
        weights=weights,
        initial_equity=initial_equity,
        final_equity=equity_curve[-1],
        total_return=total_return,
        cagr=cagr,
        volatility=volatility,
        sharpe_ratio=sharpe_ratio,
        max_drawdown=max_drawdown,
        calmar_ratio=calmar_ratio,
        trading_days=len(equity_curve) - 1,
        equity_curve=equity_curve
    )


def run_live_backtest(start, end,
                     initial_equity=DEFAULT_INITIAL_EQUITY,
                     slippage_bps=DEFAULT_SLIPPAGE_BPS,
                     noise_factor=DEFAULT_NOISE_FACTOR,
                     deposit_amount=0.0,
                     deposit_frequency=None,
                     deposit_day=1,
                     use_minute_candles=False):
    """
    Backtest using live trading configuration (config.yaml weights)
    
    Args:
        start: Start date
        end: End date
        initial_equity: Starting capital
        slippage_bps: Transaction costs in basis points
        noise_factor: Market execution noise
        deposit_amount: Regular deposit amount
        deposit_frequency: 'monthly' or 'weekly'
        deposit_day: Day for deposits
        use_minute_candles: Use minute data for execution
        
    Returns:
        BacktestResult using live trading weights
    """
    # Get current config weights
    try:
        from the_alchemiser.core.config import get_config
        config = get_config()
        weights = config['strategy'].get('default_strategy_allocations', {
            'nuclear': 0.6, 'tecl': 0.4, 'klm': 0.0
        })
    except Exception:
        weights = {'nuclear': 0.6, 'tecl': 0.4, 'klm': 0.0}
    
    console.print(Panel(
        f"[bold cyan]Live Trading Configuration Backtest[/bold cyan]\n"
        f"Period: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\n"
        f"Weights: Nuclear {weights.get('nuclear', 0)*100:.0f}%, "
        f"TECL {weights.get('tecl', 0)*100:.0f}%, "
        f"KLM {weights.get('klm', 0)*100:.0f}%\n"
        f"Initial Equity: ¬£{initial_equity:,.2f}\n"
        f"Slippage: {slippage_bps} bps | Noise: {noise_factor*100:.2f}%",
        title="üìä Live Trading Backtest"
    ))
    
    # Run core backtest (passing None uses config weights)
    equity_curve = run_core_backtest(
        start, end, None, initial_equity, slippage_bps, noise_factor,
        deposit_amount, deposit_frequency, deposit_day, use_minute_candles
    )
    
    # Calculate metrics
    total_return, cagr, volatility, sharpe_ratio, max_drawdown, calmar_ratio = \
        calculate_performance_metrics(equity_curve, initial_equity, len(equity_curve) - 1)
    
    strategy_name = f"Live ({weights.get('nuclear', 0)*100:.0f}%N/" + \
                   f"{weights.get('tecl', 0)*100:.0f}%T/" + \
                   f"{weights.get('klm', 0)*100:.0f}%K)"
    
    return BacktestResult(
        strategy_name=strategy_name,
        weights=weights,
        initial_equity=initial_equity,
        final_equity=equity_curve[-1],
        total_return=total_return,
        cagr=cagr,
        volatility=volatility,
        sharpe_ratio=sharpe_ratio,
        max_drawdown=max_drawdown,
        calmar_ratio=calmar_ratio,
        trading_days=len(equity_curve) - 1,
        equity_curve=equity_curve
    )


def run_optimized_backtest_worker(args):
    """
    Worker function that runs real strategy engines for accurate backtesting
    BUT USES CACHED DATA ONLY - NO API CALLS
    """
    weights, strategy_name, shared_data, trading_dates, initial_equity, slippage_bps, noise_factor, deposit_amount, deposit_frequency, deposit_day = args
    
    try:
        # Initialize strategy manager with the specified weights
        orig_global_config = alchemiser_config._global_config
        config_modified = False
        
        # Temporarily modify config to use these specific weights
        mock_config = alchemiser_config.Config()
        mock_config._config = copy.deepcopy(mock_config._config)
        if 'strategy' not in mock_config._config:
            mock_config._config['strategy'] = {}
        mock_config._config['strategy']['default_strategy_allocations'] = weights
        alchemiser_config._global_config = mock_config
        config_modified = True
        
        # Create a FULLY MOCKED data provider that uses only cached data
        # This prevents ANY API calls during strategy initialization
        dp = UnifiedDataProvider(paper_trading=True, cache_duration=0, enable_real_time=False)
        
        # Pre-populate the cache with our shared data to prevent API calls
        for symbol, df in shared_data.items():
            # Add to cache with different time periods
            for period in ["1y", "6mo", "3mo", "1mo", "200d"]:
                cache_key = (symbol, period, "1d")
                dp.cache[cache_key] = (0, df)  # Cache with timestamp 0 (never expires during backtest)
        
        # Mock ALL data provider methods to use cached data only
        original_methods = {}
        
        def create_mock_get_data(symbol_data_dict):
            def mock_get_data(symbol, period="1y", interval="1d"):
                if symbol in symbol_data_dict:
                    return symbol_data_dict[symbol].copy()
                return pd.DataFrame()
            return mock_get_data
        
        def create_mock_fetch_data(symbol_data_dict):
            def mock_fetch_historical_data(symbol, period="1y", interval="1d"):
                if symbol in symbol_data_dict:
                    return symbol_data_dict[symbol].copy()
                return pd.DataFrame()
            return mock_fetch_historical_data
        
        def create_mock_current_price(symbol_data_dict, current_date):
            def mock_get_current_price(symbol):
                if symbol in symbol_data_dict and current_date in symbol_data_dict[symbol].index:
                    return float(symbol_data_dict[symbol].loc[current_date, 'Close'])
                return None
            return mock_get_current_price
        
        def create_mock_latest_quote(symbol_data_dict, current_date):
            def mock_get_latest_quote(symbol):
                if symbol in symbol_data_dict and current_date in symbol_data_dict[symbol].index:
                    price = float(symbol_data_dict[symbol].loc[current_date, 'Close'])
                    return price, price  # Return same price for bid and ask
                return 0.0, 0.0
            return mock_get_latest_quote
        
        # Apply initial mocks for the full historical data
        original_methods['get_data'] = dp.get_data
        original_methods['_fetch_historical_data'] = dp._fetch_historical_data
        original_methods['get_current_price'] = dp.get_current_price
        original_methods['get_latest_quote'] = dp.get_latest_quote
        original_methods['get_historical_data'] = dp.get_historical_data
        
        dp.get_data = create_mock_get_data(shared_data)
        dp._fetch_historical_data = create_mock_fetch_data(shared_data)
        dp.get_current_price = create_mock_current_price(shared_data, trading_dates[0] if trading_dates else pd.Timestamp.now())
        dp.get_latest_quote = create_mock_latest_quote(shared_data, trading_dates[0] if trading_dates else pd.Timestamp.now())
        dp.get_historical_data = lambda symbol, start, end, timeframe=None: []
        
        # NOW create the strategy manager - it will use our mocked data provider
        manager = MultiStrategyManager(shared_data_provider=dp)
        
        # Initialize backtest variables
        equity = initial_equity
        equity_curve = [equity]
        prev_weights = {sym: 0 for sym in shared_data.keys()}
        
        # Run real strategy engines for each trading day
        for current_day in trading_dates:
            # Handle deposits
            if deposit_amount and deposit_frequency:
                if deposit_frequency == 'monthly' and current_day.day == deposit_day:
                    equity += deposit_amount
                elif deposit_frequency == 'weekly' and current_day.weekday() == deposit_day:
                    equity += deposit_amount
            
            # Mock data provider to use cached data instead of API calls
            dp.cache.clear()
            original_fetch_method = dp._fetch_historical_data
            original_get_data_method = dp.get_data
            original_get_current_price = dp.get_current_price
            original_get_current_price_for_order = dp.get_current_price_for_order
            original_get_latest_quote = dp.get_latest_quote
            original_get_historical_data = dp.get_historical_data
            
            def mock_fetch_historical_data(symbol, period="1y", interval="1d"):
                """Mock method that uses preloaded shared_data instead of API calls"""
                if symbol in shared_data:
                    df = shared_data[symbol]
                    # For backtesting, provide all available historical data up to current_day
                    # This ensures indicators like 200-day MA have enough data to work with
                    slice_df = df[df.index < current_day]
                    return slice_df
                else:
                    return pd.DataFrame()
            
            def mock_get_data(symbol, period="1y", interval="1d"):
                """Mock get_data to use cached data instead of API calls"""
                if symbol in shared_data:
                    df = shared_data[symbol]
                    # For backtesting, provide all available historical data up to current_day
                    slice_df = df[df.index < current_day]
                    return slice_df
                else:
                    return pd.DataFrame()
            
            def mock_get_current_price(symbol):
                """Mock current price using last available close price"""
                if symbol in shared_data and current_day in shared_data[symbol].index:
                    return float(shared_data[symbol].loc[current_day, 'Close'])
                return None
            
            def mock_get_current_price_for_order(symbol):
                """Mock current price for orders using last available close price"""
                price = mock_get_current_price(symbol)
                cleanup_fn = lambda: None  # No-op cleanup function
                return price, cleanup_fn
            
            def mock_get_latest_quote(symbol):
                """Mock latest quote using close price as bid/ask"""
                price = mock_get_current_price(symbol)
                if price:
                    return price, price  # Return same price for bid and ask
                return 0.0, 0.0
            
            def mock_get_historical_data(symbol, start, end, timeframe=None):
                """Mock historical data method"""
                return []  # Return empty list since we're using cached data
            
            # Apply all mocks
            dp._fetch_historical_data = mock_fetch_historical_data
            dp.get_data = mock_get_data
            dp.get_current_price = mock_get_current_price
            dp.get_current_price_for_order = mock_get_current_price_for_order
            dp.get_latest_quote = mock_get_latest_quote
            dp.get_historical_data = mock_get_historical_data
            
            # Get real strategy signals for current day
            try:
                signals, portfolio = manager.run_all_strategies()
                current_weights = {sym: portfolio.get(sym, 0.0) for sym in shared_data.keys()}
            except Exception as e:
                # Use previous weights if strategy fails
                current_weights = prev_weights.copy()
            finally:
                # Always restore original methods
                dp._fetch_historical_data = original_fetch_method
                dp.get_data = original_get_data_method
                dp.get_current_price = original_get_current_price
                dp.get_current_price_for_order = original_get_current_price_for_order
                dp.get_latest_quote = original_get_latest_quote
                dp.get_historical_data = original_get_historical_data
            
            # Calculate and apply slippage costs
            total_slippage = 0.0
            for symbol, new_weight in current_weights.items():
                old_weight = prev_weights.get(symbol, 0.0)
                weight_change = abs(new_weight - old_weight)
                
                if weight_change > 1e-6 and symbol in shared_data:
                    df = shared_data[symbol]
                    if current_day in df.index:
                        try:
                            price = float(df.loc[current_day, 'Close'])
                            if price > 0:
                                price_with_noise = _add_market_noise(price, noise_factor)
                                slippage = _calculate_slippage_cost(weight_change, price_with_noise, slippage_bps)
                                total_slippage += slippage
                        except (ValueError, TypeError):
                            continue
            
            equity *= (1 - total_slippage)
            
            # Calculate daily portfolio return
            daily_return = 0.0
            for symbol, weight in current_weights.items():
                if weight == 0 or symbol not in shared_data:
                    continue
                
                df = shared_data[symbol]
                if current_day not in df.index:
                    continue
                
                # Get previous trading day
                prev_dates = df.index[df.index < current_day]
                if len(prev_dates) == 0:
                    continue
                
                prev_day = prev_dates[-1]
                try:
                    prev_price = float(df.loc[prev_day, 'Close'])
                    curr_price = float(df.loc[current_day, 'Close'])
                    
                    if prev_price > 0:
                        symbol_return = (curr_price - prev_price) / prev_price
                        daily_return += weight * symbol_return
                except (ValueError, TypeError):
                    continue
            
            equity = float(equity * (1 + daily_return))
            equity_curve.append(equity)
            prev_weights = current_weights.copy()
        
        # Calculate metrics
        total_return, cagr, volatility, sharpe_ratio, max_drawdown, calmar_ratio = \
            calculate_performance_metrics(equity_curve, initial_equity, len(equity_curve) - 1)
        
        return BacktestResult(
            strategy_name=strategy_name,
            weights=weights,
            initial_equity=initial_equity,
            final_equity=equity_curve[-1],
            total_return=total_return,
            cagr=cagr,
            volatility=volatility,
            sharpe_ratio=sharpe_ratio,
            max_drawdown=max_drawdown,
            calmar_ratio=calmar_ratio,
            trading_days=len(equity_curve) - 1,
            equity_curve=equity_curve
        )
    except Exception as e:
        return None
    finally:
        # Restore original config
        if config_modified:
            alchemiser_config._global_config = orig_global_config


def run_all_combinations_backtest(start, end,
                                 initial_equity=DEFAULT_INITIAL_EQUITY,
                                 slippage_bps=DEFAULT_SLIPPAGE_BPS,
                                 noise_factor=DEFAULT_NOISE_FACTOR,
                                 deposit_amount=0.0,
                                 deposit_frequency=None,
                                 deposit_day=1,
                                 use_minute_candles=False,
                                 step_size=10,
                                 max_workers=4):
    """
    Optimized backtest for all weight combinations using shared data and true multithreading
    
    This version:
    1. Fetches data ONCE and shares it across all threads
    2. Uses lightweight workers that don't create new strategies
    3. Achieves 10-20x speedup over the naive approach
    
    Args:
        start: Start date
        end: End date
        initial_equity: Starting capital
        slippage_bps: Transaction costs in basis points
        noise_factor: Market execution noise
        deposit_amount: Regular deposit amount
        deposit_frequency: 'monthly' or 'weekly'
        deposit_day: Day for deposits
        use_minute_candles: Use minute data for execution
        step_size: Weight increment (10 = 10% steps)
        max_workers: Number of parallel threads
        
    Returns:
        List of BacktestResult objects for all combinations
    """
    console.print(Panel(
        f"[bold cyan]Optimized All Weight Combinations Backtest[/bold cyan]\n"
        f"Period: {start.strftime('%Y-%m-%d')} to {end.strftime('%Y-%m-%d')}\n"
        f"Step Size: {step_size}%\n"
        f"Threads: {max_workers} (with shared data)\n"
        f"Initial Equity: ¬£{initial_equity:,.2f}\n"
        f"Slippage: {slippage_bps} bps | Noise: {noise_factor*100:.2f}%",
        title="ÔøΩ Optimized All Combinations Test"
    ))
    
    # Step 1: Fetch data ONCE and share across all threads
    dp = UnifiedDataProvider(paper_trading=True, cache_duration=0)
    manager = MultiStrategyManager(shared_data_provider=dp)
    
    # Get all required symbols
    all_syms = list(set(
        manager.nuclear_engine.all_symbols + 
        manager.tecl_engine.all_symbols +
        (manager.klm_ensemble.all_symbols if hasattr(manager, 'klm_ensemble') and manager.klm_ensemble else [])
    ))
    
    # Preload data into cache first
    lookback_days = 400 if use_minute_candles else 1200
    data_start = start - dt.timedelta(days=lookback_days)
    
    shared_data, minute_data = preload_backtest_data(
        data_start, end, 
        symbols=all_syms,
        include_minute_data=use_minute_candles,
        force_refresh=False
    )
    
    # Use the preloaded data directly instead of calling _get_cached_symbol_data again
    # shared_data is already the dictionary we need
    
    if not shared_data:
        raise ValueError("No symbol data loaded - check data provider and symbols")
    
    # Get trading dates
    all_trading_dates = set()
    for sym in ['SPY', 'QQQ']:
        if sym in shared_data and not shared_data[sym].empty:
            df = shared_data[sym]
            # Handle timezone issues
            start_tz = start
            end_tz = end
            if df.index.tz is not None:
                import pytz
                if start.tzinfo is None:
                    start_tz = pytz.timezone('US/Eastern').localize(start)
                if end.tzinfo is None:
                    end_tz = pytz.timezone('US/Eastern').localize(end)
            else:
                if start.tzinfo is not None:
                    start_tz = start.replace(tzinfo=None)
                if end.tzinfo is not None:
                    end_tz = end.replace(tzinfo=None)
                    
            date_mask = (df.index >= start_tz) & (df.index <= end_tz)
            all_trading_dates.update(df.index[date_mask])
    
    trading_dates = sorted(all_trading_dates)
    
    if not trading_dates:
        raise ValueError(f"No trading data found for period {start.date()} to {end.date()}")
    
    console.print(f"[green]‚úì Shared data ready: {len(shared_data)} symbols, {len(trading_dates)} trading days")
    
    # Step 2: Generate all valid weight combinations
    combinations = []
    for nuclear in range(0, 101, step_size):
        for tecl in range(0, 101 - nuclear, step_size):
            klm = 100 - nuclear - tecl
            if klm >= 0:
                weights = {
                    'nuclear': nuclear / 100.0,
                    'tecl': tecl / 100.0,
                    'klm': klm / 100.0
                }
                strategy_name = f"{nuclear}%N/{tecl}%T/{klm}%K"
                # Pack all arguments for the worker
                worker_args = (weights, strategy_name, shared_data, trading_dates, 
                             initial_equity, slippage_bps, noise_factor, 
                             deposit_amount, deposit_frequency, deposit_day)
                combinations.append(worker_args)
    
    console.print(f"[yellow]Running {len(combinations)} combinations with optimized multithreading...")
    
    # Step 3: Run with optimized multithreading
    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        from rich.progress import BarColumn, TimeRemainingColumn, MofNCompleteColumn
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            MofNCompleteColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeRemainingColumn(),
            console=console
        ) as progress:
            task = progress.add_task("Running combinations...", total=len(combinations))
            
            # Submit all jobs
            future_to_combo = {executor.submit(run_optimized_backtest_worker, combo): combo 
                              for combo in combinations}
            
            # Collect results as they complete
            for future in as_completed(future_to_combo):
                result = future.result()
                if result:
                    results.append(result)
                progress.advance(task)
    
    # Sort by Sharpe ratio
    results.sort(key=lambda x: x.sharpe_ratio, reverse=True)
    
    # Display top 10 results
    table = Table(title="üèÜ Top 10 Weight Combinations (by Sharpe Ratio)")
    table.add_column("Rank", style="cyan")
    table.add_column("Strategy", style="yellow")
    table.add_column("Total Return", style="green")
    table.add_column("CAGR", style="blue")
    table.add_column("Volatility", style="magenta")
    table.add_column("Sharpe Ratio", style="red")
    table.add_column("Max DD", style="red")
    
    for i, result in enumerate(results[:10], 1):
        table.add_row(
            str(i),
            result.strategy_name,
            f"{result.total_return:+.2f}%",
            f"{result.cagr:.2f}%",
            f"{result.volatility:.2f}%",
            f"{result.sharpe_ratio:.2f}",
            f"{result.max_drawdown:.2f}%"
        )
    
    console.print(table)
    console.print(f"[green]‚úÖ Completed {len(results)} successful backtests with shared data optimization")
    return results

# CLI integration for direct module execution
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Clean Backtest Engine for The Alchemiser")
    parser.add_argument('--start', type=str, default='2025-01-01', help='Start date (YYYY-MM-DD, default: 2025-01-01)')
    parser.add_argument('--end', type=str, default=(dt.datetime.now() - dt.timedelta(days=3)).strftime('%Y-%m-%d'), help='End date (YYYY-MM-DD, default: 3 days ago)')
    parser.add_argument('--mode', choices=['individual', 'live', 'all'], default='live',
                       help='Backtest mode: individual strategy, live trading config, or all combinations')
    parser.add_argument('--strategy', choices=['nuclear', 'tecl', 'klm'], 
                       help='Strategy for individual mode')
    parser.add_argument('--initial-equity', type=float, default=DEFAULT_INITIAL_EQUITY,
                       help=f'Initial equity (default: {DEFAULT_INITIAL_EQUITY})')
    parser.add_argument('--slippage-bps', type=float, default=DEFAULT_SLIPPAGE_BPS,
                       help=f'Slippage in basis points (default: {DEFAULT_SLIPPAGE_BPS})')
    parser.add_argument('--noise-factor', type=float, default=DEFAULT_NOISE_FACTOR,
                       help=f'Market noise factor (default: {DEFAULT_NOISE_FACTOR})')
    parser.add_argument('--deposit-amount', type=float, default=0.0, help='Regular deposit amount')
    parser.add_argument('--deposit-frequency', choices=['monthly', 'weekly'], help='Deposit frequency')
    parser.add_argument('--deposit-day', type=int, default=1, help='Deposit day')
    parser.add_argument('--step-size', type=int, default=10, help='Weight step size for all-combinations mode')
    parser.add_argument('--max-workers', type=int, default=4, help='Max threads for parallel execution')
    parser.add_argument('--use-processes', action='store_true', help='Use multiprocessing instead of threading (may be faster for CPU-intensive tasks)')
    parser.add_argument('--use-minute-candles', action='store_true', help='Use minute candles for execution')
    
    args = parser.parse_args()
    
    # Parse dates
    start_dt = dt.datetime.strptime(args.start, "%Y-%m-%d")
    end_dt = dt.datetime.strptime(args.end, "%Y-%m-%d")
    
    # Run appropriate backtest
    if args.mode == 'individual':
        if not args.strategy:
            console.print("[red]Error: --strategy required for individual mode")
            exit(1)
        result = run_individual_strategy_backtest(
            args.strategy, start_dt, end_dt,
            initial_equity=args.initial_equity,
            slippage_bps=args.slippage_bps,
            noise_factor=args.noise_factor,
            deposit_amount=args.deposit_amount,
            deposit_frequency=args.deposit_frequency,
            deposit_day=args.deposit_day,
            use_minute_candles=args.use_minute_candles
        )
        
        # Display results
        table = Table(title="üìà Individual Strategy Backtest Results")
        table.add_column("Metric", style="cyan")
        table.add_column("Value", style="green")
        
        table.add_row("Strategy", result.strategy_name)
        table.add_row("Final Equity", f"¬£{result.final_equity:,.2f}")
        table.add_row("Total Return", f"{result.total_return:+.2f}%")
        table.add_row("CAGR", f"{result.cagr:.2f}%")
        table.add_row("Volatility", f"{result.volatility:.2f}%")
        table.add_row("Sharpe Ratio", f"{result.sharpe_ratio:.2f}")
        table.add_row("Max Drawdown", f"{result.max_drawdown:.2f}%")
        table.add_row("Calmar Ratio", f"{result.calmar_ratio:.2f}" if result.calmar_ratio != float('inf') else "‚àû")
        table.add_row("Trading Days", str(result.trading_days))
        
        console.print(table)
        
    elif args.mode == 'live':
        result = run_live_backtest(
            start_dt, end_dt,
            initial_equity=args.initial_equity,
            slippage_bps=args.slippage_bps,
            noise_factor=args.noise_factor,
            deposit_amount=args.deposit_amount,
            deposit_frequency=args.deposit_frequency,
            deposit_day=args.deposit_day,
            use_minute_candles=args.use_minute_candles
        )
        
        # Display results
        table = Table(title="üìà Live Trading Configuration Results")
        table.add_column("Metric", style="cyan")
        table.add_column("Value", style="green")
        
        table.add_row("Strategy", result.strategy_name)
        table.add_row("Final Equity", f"¬£{result.final_equity:,.2f}")
        table.add_row("Total Return", f"{result.total_return:+.2f}%")
        table.add_row("CAGR", f"{result.cagr:.2f}%")
        table.add_row("Volatility", f"{result.volatility:.2f}%")
        table.add_row("Sharpe Ratio", f"{result.sharpe_ratio:.2f}")
        table.add_row("Max Drawdown", f"{result.max_drawdown:.2f}%")
        table.add_row("Calmar Ratio", f"{result.calmar_ratio:.2f}" if result.calmar_ratio != float('inf') else "‚àû")
        table.add_row("Trading Days", str(result.trading_days))
        
        console.print(table)
        
    elif args.mode == 'all':
        results = run_all_combinations_backtest(
            start_dt, end_dt,
            initial_equity=args.initial_equity,
            slippage_bps=args.slippage_bps,
            noise_factor=args.noise_factor,
            deposit_amount=args.deposit_amount,
            deposit_frequency=args.deposit_frequency,
            deposit_day=args.deposit_day,
            use_minute_candles=args.use_minute_candles,
            step_size=args.step_size,
            max_workers=args.max_workers
        )
        # Results are already displayed in the function
    
    console.print("\n[bold green]‚úÖ Backtest complete![/bold green]")
